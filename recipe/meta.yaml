{% set version = "2.4" %}
{% set torch_proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

{% if cuda_compiler_version in (None, "None", True, False) %}
{% set cuda_major = 0 %}
{% else %}
{% set cuda_major = environ.get("cuda_compiler_version", "11.8").split(".")[0] | int %}
{% endif %}

package:
  name: transformer-engine
  version: {{ version }}

source:
  - url: https://github.com/NVIDIA/TransformerEngine/archive/refs/tags/v{{ version }}.tar.gz
    sha256: c686f09b4e8a0f58351aa7ebd0afbd8567dbffeae5cd4a3341793f255cf0d69b
    patches:
      - 001-cmake.patch

  - url: https://github.com/NVIDIA/cudnn-frontend/archive/refs/tags/v1.11.0.tar.gz
    sha256: de723e07582603721c97dd4fd82bbad0020fa830d1d1eee6269ebf6950ed3128
    folder: 3rdparty/cudnn-frontend

  - url: https://github.com/google/googletest/archive/refs/tags/v1.14.0.tar.gz
    sha256: 8ad598c73ad796e0d8280b082cebd82a630d73e73cd3c70057938a6501bba5d7
    folder: 3rdparty/googletest

build:
  number: 0

outputs:
  - name: transformer-engine-torch
    version: {{ version }}
    script: build_te.sh

    build:
      skip: true  # [py==39]
      skip: true  # [not (cuda_compiler_version or "").startswith("12")]
      skip: true  # [not (linux64 or aarch64)]
      script_env:
        - CUDA_HOME={{ BUILD_PREFIX }}
        - NVTE_FRAMEWORK=pytorch

      run_exports:
        - {{ pin_subpackage('transformer-engine-torch', max_pin='x.x') }}

    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - pytorch                                # [build_platform != target_platform]
        - pytorch =*={{ torch_proc_type }}*      # [build_platform != target_platform]
        - {{ stdlib('c') }}
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler_version not in (undefined, 'None')]
        - cuda-nvvm
        - cmake >=3.21
        - ninja

      host:
        - python
        - pip
        - pybind11
        - pytorch
        - pytorch =*={{ torch_proc_type }}*
        - setuptools
        - pydantic
        - importlib-metadata >=1.0
        - packaging
        - cuda-driver-dev
        - cuda-cudart-dev
        - cuda-nvrtc-dev
        - cuda-nvtx-dev
        - cuda-nvml-dev
        - libcublas-dev
        - libcusparse-dev
        - libcusolver-dev
        - libcudnn-dev
        - cudnn
        - cuda-profiler-api

      run:
        - python
        - pydantic
        - packaging
        - importlib-metadata >=1.0
        - einops

      run_constrained:
        # additional run constraint to the one from the (version-only) run_export;
        # constraining the CPU builds to CPU pytorch isn't 100% necessary, but cleaner
        - pytorch =*={{ torch_proc_type }}*

    test:
      imports:
        - transformer_engine.pytorch
        - transformer_engine.common
        - transformer_engine.common.recipe

about:
  home: https://github.com/NVIDIA/TransformerEngine
  summary: A library for accelerating Transformer models on NVIDIA GPUs.
  license: Apache-2.0
  license_file: LICENSE
  dev_url: https://github.com/NVIDIA/TransformerEngine

extra:
  feedstock-name: transformer-engine
  recipe-maintainers:
    - pstjohn
